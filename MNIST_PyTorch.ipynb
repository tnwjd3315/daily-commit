{
  "cells": [
    {
      "metadata": {
        "id": "3d31a6229913041"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementing Convolutional Neural Network (CNN) with MNIST data"
      ],
      "id": "3d31a6229913041"
    },
    {
      "metadata": {
        "id": "bd3980a8bd50b6b1"
      },
      "cell_type": "markdown",
      "source": [
        "CNN is composed of following components:\n",
        "- CNN: extracts features from an image\n",
        "- Max Pooling: reduces features from an image\n",
        "- Fully Connected Network: uses extracted and reduced features as input to perform downstream tasks."
      ],
      "id": "bd3980a8bd50b6b1"
    },
    {
      "metadata": {
        "id": "f913eabc95de2956"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "id": "f913eabc95de2956"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-16T07:37:38.559966Z",
          "start_time": "2025-04-16T07:37:38.189208Z"
        },
        "id": "33d50f5c4940037"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn # 신경망들이 포함됨\n",
        "import torch.optim as optim # 최적화 알고리즘들이 포함됨\n",
        "import torch.nn.init as init # 텐서에 초기값을 줌\n",
        "\n",
        "import torchvision.datasets as datasets # 이미지 데이터셋 집합체\n",
        "import torchvision.transforms as transforms # 이미지 변환 툴\n",
        "\n",
        "from torch.utils.data import DataLoader # 학습 및 배치로 모델에 넣어주기 위한 툴\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "33d50f5c4940037",
      "outputs": [],
      "execution_count": 1
    },
    {
      "metadata": {
        "id": "19507157085189e7"
      },
      "cell_type": "markdown",
      "source": [
        "## Set Hyperparameter"
      ],
      "id": "19507157085189e7"
    },
    {
      "metadata": {
        "id": "7b66ca5211575ecb"
      },
      "cell_type": "markdown",
      "source": [
        "- batch_size: how many data samples are used in one batch. The dataset split into these small batches.\n",
        "- learning_rate: controls how big each step is when the model learns. It decides how fast the training moves toward the best answer.\n",
        "- num_epoch: One epoche menas the model has seen the whole dataset once and trained on it. Number of epochs tells how many times the model will go through the full dataset."
      ],
      "id": "7b66ca5211575ecb"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "metadata": {
        "id": "qdNpeYhjjkx7"
      },
      "id": "qdNpeYhjjkx7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST Data"
      ],
      "metadata": {
        "id": "kW7NdmuUj-_5"
      },
      "id": "kW7NdmuUj-_5"
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = datasets.MNIST(root=\"../Data/\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = datasets.MNIST(root=\"../Data/\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1MjWVolj6f0",
        "outputId": "0baa548d-7ce0-40f0-8da0-6aa6f525247f"
      },
      "id": "p1MjWVolj6f0",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.73MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.82MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Loaders"
      ],
      "metadata": {
        "id": "gYxGBnrJkQkb"
      },
      "id": "gYxGBnrJkQkb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader is a tool that helps load data in batches for training or testing the model. When we put a dataset into the DataLoader, it gives the data to the model step by step, based on the settings we choose (like batch size)."
      ],
      "metadata": {
        "id": "PPYMifNakmEP"
      },
      "id": "PPYMifNakmEP"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "qT732uzOkUMT"
      },
      "id": "qT732uzOkUMT",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CNN (Base) Model"
      ],
      "metadata": {
        "id": "cBhde0tFkxKo"
      },
      "id": "cBhde0tFkxKo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first, define the CNN class, using torch.nn.Module"
      ],
      "metadata": {
        "id": "7s3Hg8ckk0V8"
      },
      "id": "7s3Hg8ckk0V8"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__() #initialize nn.Module\n",
        "\n",
        "    self.layer = nn.Sequential(\n",
        "        # extract features from the image using learnable filters\n",
        "        # [100,1,28,28] -> [100,16,24,24]\n",
        "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),\n",
        "\n",
        "        #activation function that introduces non-linearity into the model\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # [100,16,24,24]->[100,32,20,20]\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        #[100,32,20,20]->[100,32,10,10]\n",
        "        #reduces the spatial dimensions of the feature maps, helping to make the model more robust to small variations in the input\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        #[100,32,10,10]->[100,64,6,6]\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # [100,64,6,6]->[100,64,3,3]\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    # fully connected layers\n",
        "    self.fc_layer = nn.Sequential(\n",
        "        # each neuron is connected to every neuron in the previous layer\n",
        "        #[100,64*3*3] -> [100,100]\n",
        "        nn.Linear(64*3*3, 100),\n",
        "        nn.ReLU(),\n",
        "        #[100,100] -> [100,10]\n",
        "        nn.Linear(100,10)\n",
        "    )\n",
        "\n",
        "  #defines how the input data (x) flows through the network\n",
        "  def forward(self,x):\n",
        "    out = self.layer(x)\n",
        "    out = out.view(batch_size, -1) #convert the shape of the tensor to [100,remainder] using view()\n",
        "    out = self.fc_layer(out)\n",
        "    return out\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "d8caED2rkpEz"
      },
      "id": "d8caED2rkpEz",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU or CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "f7dHkYR4rJwl"
      },
      "id": "f7dHkYR4rJwl",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "s_n_MjaJrkzc"
      },
      "id": "s_n_MjaJrkzc",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function and Optimizer"
      ],
      "metadata": {
        "id": "zeWAbeGcrnV2"
      },
      "id": "zeWAbeGcrnV2"
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Qx7FgLZhrlNU"
      },
      "id": "Qx7FgLZhrlNU",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "gsvkEsLiryW2"
      },
      "id": "gsvkEsLiryW2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In train_loader, we get a batch of image and label pairs and send them to the model. The model uses them to calculate the loss. Then, it updates the model using gradient descent based on the loss. Every 1000 iterations, we print the loss and save it to loss_arr."
      ],
      "metadata": {
        "id": "BXMQOGbpsBrT"
      },
      "id": "BXMQOGbpsBrT"
    },
    {
      "cell_type": "code",
      "source": [
        "loss_arr = []\n",
        "\n",
        "for i in range(num_epoch):\n",
        "\n",
        "  # enumerate(): to get the batch index j and the image,label-pair\n",
        "  for j,[image, label] in enumerate(train_loader):\n",
        "    x = image.to(device)\n",
        "    y = label.to(device)\n",
        "\n",
        "    # Gradient Calculation and Update\n",
        "    optimizer.zero_grad() # reset gradients to 0\n",
        "\n",
        "    # pass the input image data (x) through the CNN model (model.forward) to get the model's predictions (output)\n",
        "    output = model.forward(x)\n",
        "\n",
        "    loss = loss_func(output, y)\n",
        "\n",
        "    loss.backward() # calculate the gradients of the loss\n",
        "\n",
        "    # update the model's parameters based on the calculated gradients to minimize the loss.\n",
        "    optimizer.step()\n",
        "\n",
        "    # Logging and Monitoring\n",
        "    if j % 1000 == 0:\n",
        "      print(loss)\n",
        "\n",
        "      # convert the loss tensor to a NumPy array and appends it to the loss_arr.\n",
        "      # cpu() moves the tensor to the CPU, detach() detaches it from the computation graph, and numpy() converts it to a NumPy array.\n",
        "      loss_arr.append(loss.cpu().detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK-7d6gKrwj0",
        "outputId": "60dd3830-3ab7-436a-9160-675e66849d60"
      },
      "id": "FK-7d6gKrwj0",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3084, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2982, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2985, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3080, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3011, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2998, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3009, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.3007, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2961, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2873, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "sRVtpzYQuueB"
      },
      "id": "sRVtpzYQuueB"
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Setting the Model to Evaluation Mode\n",
        "model.eval()\n",
        "\n",
        "# torch.no_grad(): Disabling Gradient Calculation\n",
        "# make the code faster and use less memory\n",
        "with torch.no_grad():\n",
        "  for image, label in test_loader:\n",
        "    x = image.to(device)\n",
        "    y = label.to(device)\n",
        "\n",
        "    output = model.forward(x)\n",
        "\n",
        "    # maximum, index\n",
        "    _, output_index = torch.max(output, 1)\n",
        "\n",
        "    total += label.size(0)\n",
        "    correct += (output_index == y).sum().float() #when index = label, add to correct\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h40CjYJut4e",
        "outputId": "f56b93a9-de0b-46d0-f4cd-58797f3390fc"
      },
      "id": "3h40CjYJut4e",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 19.469999313354492\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}